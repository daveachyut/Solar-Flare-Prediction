{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (properties.py, line 185)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2862\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-14-957de6d73758>\"\u001b[0m, line \u001b[0;32m9\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from flaregress.io import DatabaseHandler\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\ML\\Project\\flaregress-master\\flaregress-master\\flaregress\\io.py\"\u001b[0m, line \u001b[0;32m9\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from sunpy.instr.goes import get_goes_event_list\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sunpy\\instr\\goes.py\"\u001b[0m, line \u001b[0;32m63\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from sunpy.net import hek\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sunpy\\net\\__init__.py\"\u001b[0m, line \u001b[0;32m5\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from sunpy.net.fido_factory import Fido\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sunpy\\net\\fido_factory.py\"\u001b[0m, line \u001b[0;32m20\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from sunpy.net.dataretriever.clients import CLIENTS\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sunpy\\net\\dataretriever\\__init__.py\"\u001b[0m, line \u001b[0;32m11\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from .client import QueryResponseBlock, QueryResponse, GenericClient\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sunpy\\net\\dataretriever\\client.py\"\u001b[0m, line \u001b[0;32m35\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from sunpy.net.vso.attrs import Time, Wavelength, _Range\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sunpy\\net\\vso\\__init__.py\"\u001b[0m, line \u001b[0;32m4\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from sunpy.net.vso.vso import VSOClient, InteractiveVSOClient, QueryResponse\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sunpy\\net\\vso\\vso.py\"\u001b[0m, line \u001b[0;32m34\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from sunpy.net.proxyfix import WellBehavedHttpTransport\n",
      "  File \u001b[0;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sunpy\\net\\proxyfix.py\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from suds.transport.http import HttpTransport as SudsHttpTransport\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\suds\\transport\\http.py\"\u001b[1;36m, line \u001b[1;32m26\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from suds.properties import Unskin\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\suds\\properties.py\"\u001b[1;36m, line \u001b[1;32m185\u001b[0m\n\u001b[1;33m    except (AttributeError)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov 21 18:56:39 2018\n",
    "\n",
    "@author: Admin\n",
    "\"\"\"\n",
    "\n",
    "# LSTM for problem with regression framing\n",
    "from flaregress.io import DatabaseHandler\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import h5py\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import concatenate\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset):\n",
    "    #dataX, dataY = [], []\n",
    "    # Process data for ARIMA\n",
    "    split_fraction = 0.67\n",
    "    split = int(len(db.entries[entry_number]['xrs'].values) * split_fraction)\n",
    "    training_stream = [x[0] for x in db.entries[entry_number]['xrs'].values[:split]]\n",
    "    test_stream = [x[0] for x in db.entries[entry_number]['xrs'].values[split:]]\n",
    "    #print(np.shape(dataX))\n",
    "    #print(dataY)\n",
    "    return (training_stream), (test_stream)\n",
    "def read_dataset(file):\n",
    "    # Load database from h5 file\n",
    "    db = DatabaseHandler()\n",
    "    read=db.load(file)\n",
    "    return read\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# load the dataset\n",
    "dataframe = read_dataset('db.h5')\n",
    "dataset = pd.DataFrame(dataframe)#, index=list('ABCDEFGH')\n",
    "dataset = dataset.astype('float32')\n",
    "#print(dataset)\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "#print(train)\n",
    "#print(test)\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 6\n",
    "trainX, trainY = create_dataset(train)\n",
    "testX, testY = create_dataset(test)\n",
    "trainX=np.asarray(trainX)\n",
    "trainY=np.asarray(trainY)\n",
    "testX=np.asarray(testX)\n",
    "testY=np.asarray(testY)\n",
    "print(trainX.shape)\n",
    "#print(trainY)\n",
    "#print(testX)\n",
    "#print(testY)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX[:,:,:], (3642, 1, 4))\n",
    "trainY = np.reshape(trainY[:,:,:], (3642, 1, 4))\n",
    "testX = np.reshape(testX, (1794, 1, 4))\n",
    "testY = np.reshape(testX, (1794, 1, 4))\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(trainX.shape[1],trainX.shape[2]), return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "z=[]\n",
    "for i in range(len(trainY)):\n",
    "    z.append(trainY[i][0][0])\n",
    "print(len(z))\n",
    "z=np.asarray(z)\n",
    "w=[]\n",
    "for j in range(len(testY)):\n",
    "    w.append(testY[j][0][0])\n",
    "print(len(w))\n",
    "w=np.asarray(w)\n",
    "print(np.shape(w))\n",
    "checkpoint = ModelCheckpoint(filepath='C:/Users/Admin/Anaconda3/ML/Project/weights.hdf5', monitor='val_acc', verbose=0, save_best_only=False, mode='max')\n",
    "history = model.fit(trainX[:,:,:], z, epochs=7, batch_size=24, verbose=2, validation_data=(testX, w))\n",
    "#, callbacks=[checkpoint]\n",
    "#history = model.fit(trainX[:,:,:], z, epochs=100, batch_size=12, verbose=2, validation_split=0.2)\n",
    "# make predictions\n",
    "#history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "#for i in range(epochs):\n",
    "acc=history.history['loss']\n",
    "for i in range(len(acc)):\n",
    "    acc[i]=(acc[i])/(5*math.exp(-8))\n",
    "plt.plot(acc, label='train')\n",
    "val_acc=history.history['val_loss']\n",
    "for i in range(len(val_acc)):\n",
    "    val_acc[i]=(val_acc[i])/(5*math.exp(-8))\n",
    "plt.plot(val_acc, label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(testX)\n",
    "print(np.shape(yhat))\n",
    "print(np.shape(testX[:,:,0]))\n",
    "testX = testX.reshape((testX.shape[0], 4))\n",
    "print(np.shape(testX[:,[0]]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, testX[:,[0]]), axis=1)\n",
    "#inv_yhat = scaler.inverse_transform(inv_yhat[:,:].reshape(12,1)).reshape(12,1)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "testY = testY.reshape((len(testY), 4))\n",
    "inv_y = np.concatenate((testY, testX[:, [0]]), axis=1)\n",
    "#inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
